{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7375e1fd",
   "metadata": {},
   "source": [
    "# [Data science] Crypto Currency Predition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b901978",
   "metadata": {},
   "source": [
    "# 1 - Ethereum Historical Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb967c7",
   "metadata": {},
   "source": [
    "Here is an example of how you could retrieve historical data on Ethereum using the CryptoCompare API in Python using the basic plan:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fa3a228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'time': 1500940800, 'high': 225.98, 'low': 192.64, 'open': 225.48, 'volumefrom': 1382784.11, 'volumeto': 285374761.65, 'close': 203.59, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501027200, 'high': 209.29, 'low': 193.1, 'open': 203.59, 'volumefrom': 809346.64, 'volumeto': 161659275.04, 'close': 202.88, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501113600, 'high': 205.68, 'low': 198.93, 'open': 202.88, 'volumefrom': 504777.47, 'volumeto': 102009361.91, 'close': 202.93, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501200000, 'high': 203.93, 'low': 189.77, 'open': 202.93, 'volumefrom': 631780.7, 'volumeto': 123425467.06, 'close': 191.21, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501286400, 'high': 209.57, 'low': 177.69, 'open': 191.21, 'volumefrom': 1010020.82, 'volumeto': 192325102.02, 'close': 206.14, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501372800, 'high': 209.88, 'low': 194.12, 'open': 206.14, 'volumefrom': 553749.07, 'volumeto': 110586575.75, 'close': 196.78, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501459200, 'high': 201.78, 'low': 190.53, 'open': 196.78, 'volumefrom': 528822.67, 'volumeto': 103641349.39, 'close': 201.33, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501545600, 'high': 232.55, 'low': 201.27, 'open': 201.33, 'volumefrom': 1444224.2, 'volumeto': 314260050.78, 'close': 225.9, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501632000, 'high': 228.98, 'low': 215.71, 'open': 225.9, 'volumefrom': 557162.98, 'volumeto': 122967812.49, 'close': 218.12, 'conversionType': 'direct', 'conversionSymbol': ''}, {'time': 1501718400, 'high': 228.08, 'low': 217.84, 'open': 218.12, 'volumefrom': 417327.69, 'volumeto': 93201219.53, 'close': 224.39, 'conversionType': 'direct', 'conversionSymbol': ''}]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the endpoint for the CryptoCompare API\n",
    "url = 'https://min-api.cryptocompare.com/data/histoday'\n",
    "\n",
    "# Define the parameters for the API request\n",
    "parameters = {\n",
    "    'fsym': 'ETH',\n",
    "    'tsym': 'USD',\n",
    "    'limit': '2000'\n",
    "}\n",
    "\n",
    "# Make the API request\n",
    "response = requests.get(url, params=parameters)\n",
    "\n",
    "# Parse the response\n",
    "data = json.loads(response.text)\n",
    "\n",
    "# Print the historical data\n",
    "print(data['Data'][:10])   #Only Showing first 10 values just for confirmation\n",
    "\n",
    "#The data variable contains 2000 records which have been extrected from the CryptoCompare API\n",
    "#Note: This Free web-API doesn't allow us to extract more than 2000 records"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2597212",
   "metadata": {},
   "source": [
    "## Converting JSON to CSV and Exporting as .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f33e91",
   "metadata": {},
   "source": [
    "You can use the pandas library to convert the JSON data returned from the API into a CSV file. Here's an example of how you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "107ea10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.DataFrame(data['Data'])\n",
    "\n",
    "# Convert the DataFrame to a CSV file\n",
    "df.to_csv('eth_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d0a62",
   "metadata": {},
   "source": [
    "This code creates a new CSV file called \"eth_data.csv\" in the same directory as your script, with the data from the API response. The index=False argument tells pandas to not include the DataFrame's index in the output CSV file.\n",
    "\n",
    "Please note that the data structure of the API response may be different, you may need to adjust the code accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9868c858",
   "metadata": {},
   "source": [
    "# 2 - Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b0ddc",
   "metadata": {},
   "source": [
    "For machine learning model you can use any algorithm such as Linear Regression, Random Forest, LSTM etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d33b877",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2442.89        432.97       1805.49        169.98000001 1597.44\n",
      " 1367.65        258.79       2963.17        302.77        242.08\n",
      "  283.          206.78       2531.75        135.56        417.76\n",
      "  661.45        206.          434.85       2114.51       3569.26\n",
      "  254.66       1848.69       1210.59        239.54       1833.26\n",
      "  289.42        346.94        111.34000001  170.38000001  317.4       ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data into a pandas DataFrame\n",
    "df = pd.read_csv('eth_data.csv')\n",
    "\n",
    "# Define the features and target\n",
    "X = df[['high', 'low', 'open','volumefrom','volumeto', 'close']]\n",
    "y = df['close']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Train the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(y_pred[:30])   #Only Showing first 30 predictions just for confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6030ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's performance\n",
    "score = model.score(X_test, y_test)\n",
    "print(f'R^2 score: {score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350818af",
   "metadata": {},
   "source": [
    "Please be aware that using a free/basic plan API will limit the amount of data you can retrieve and the accuracy of predictions will be low. Also, for machine learning model, you need to pre-process the data and use feature engineering techniques to improve the accuracy of predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ff948",
   "metadata": {},
   "source": [
    "# 3 - Predict Future Prices and Store in a DB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8fcb75",
   "metadata": {},
   "source": [
    "Yes, you can use the trained model to make predictions on new, unseen data and store those predictions in a database.\n",
    "\n",
    "Here is an example of how you could use a Jupyter notebook to make predictions using a trained model and store those predictions in a SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "183119ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make predictions using the trained model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions to a DataFrame\n",
    "predictions_df = pd.DataFrame(y_pred, columns=['predicted_price'])\n",
    "\n",
    "# Import the SQLite3 library\n",
    "import sqlite3\n",
    "\n",
    "# Connect to a SQLite database\n",
    "conn = sqlite3.connect('predictions.db')\n",
    "\n",
    "# Store the predictions in a SQLite table\n",
    "predictions_df.to_sql('predictions', conn, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ba6d2",
   "metadata": {},
   "source": [
    "This code makes predictions on the test data using the trained model, and converts the predictions to a DataFrame. Then, it imports the SQLite3 library, connects to a SQLite database called 'predictions.db', and stores the predictions in a table called 'predictions' in the database.\n",
    "\n",
    "It's worth noting that you can also use other databases such as MySQL, PostgreSQL, MongoDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a98517d",
   "metadata": {},
   "source": [
    "### Getting records from the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5828e53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  predicted_price\n",
      "0      0          2442.89\n",
      "1      1           432.97\n",
      "2      2          1805.49\n",
      "3      3           169.98\n",
      "4      4          1597.44\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the 'predictions' table into a DataFrame\n",
    "predictions_df = pd.read_sql_query('SELECT * FROM predictions', conn)\n",
    "\n",
    "# Print the first 5 rows of the DataFrame\n",
    "print(predictions_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfadda6",
   "metadata": {},
   "source": [
    "# 4 - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62c2fdc",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE) are commonly used metrics for evaluating the accuracy of time series predictions.\n",
    "\n",
    "MAE measures the average difference between the predicted and actual values. It gives an idea of how far off the predictions are from the actual values.\n",
    "MSE measures the average squared difference between the predicted and actual values. It gives more weight to larger errors.\n",
    "RMSE is the square root of MSE. It is used to interpret the model's performance in the same units as the original data.\n",
    "You can use the mean_absolute_error(), mean_squared_error(), and sqrt() functions from the sklearn.metrics module to calculate these metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3c85b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.940252221564995e-09\n",
      "MSE: 7.25761981256719e-18\n",
      "RMSE: 2.6939969956492507e-09\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate MAE\n",
    "mae = mean_absolute_error(y_test, predictions_df['predicted_price'])\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, predictions_df['predicted_price'])\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = sqrt(mse)\n",
    "\n",
    "# Print the results\n",
    "print(f'MAE: {mae}')\n",
    "print(f'MSE: {mse}')\n",
    "print(f'RMSE: {rmse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ced9a22",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c769df",
   "metadata": {},
   "source": [
    "For regression problems, instead of using accuracy as a performance metric, you can use metrics such as Mean Absolute Error (MAE), Mean Squared Error (MSE), and Root Mean Squared Error (RMSE). These metrics give you an idea of how close the predicted values are to the actual values.\n",
    "\n",
    "Another way to check the accuracy of your prediction is to check the correlation between your predicted values and the actual values. You can use the r2_score() function from sklearn.metrics to check the correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3833cef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R-squared score\n",
    "r2 = r2_score(y_test, predictions_df['predicted_price'])\n",
    "\n",
    "# Print the R-squared score\n",
    "print(f'R-squared score: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27374bde",
   "metadata": {},
   "source": [
    "This will give you a value between -1 and 1, where 1 means a perfect positive correlation and -1 means a perfect negative correlation. The closer the value is to 1, the better the model is at predicting the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb835e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
